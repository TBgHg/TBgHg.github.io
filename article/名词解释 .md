# 计算机软件概念：

## Unix、Linux、Ubuntu、CentOS、MacOS、Android及其之间的关系

### Unix :

Unix是一种多用户、多任务的操作系统，支持多种CPU架构，最早于贝尔实验室开发。按操作系统分类，属于分时操作系统。拥有分时系统的计算机在处理多个用户发送出的指令时，计算机会把它的运行时间分为多个时间段，并且将这些时间段平均分配给用户们指定的任务，轮流的为每一个任务运行一定的时间，如此循环直到完成所有任务。

### MacOS :

MacOS是基于Unix内核的图形化操作系统，由苹果公司推出，为麦金塔计算机专用，自2002年起在所有Mac计算机预装。另外，电脑病毒几乎都是针对Windows的，由于MAC的架构和Windows不同，所以很少受到病毒的袭击。

### Linux :

Linux是一种自由和开放源代码的类Unix系统。只要遵循GNU公共许可证，任何个人和机构都可以自由地使用Linux的所有底层源代码，也可以自由地修改和再发布。Linux严格来说只是指操作系统的内核，但如今Linux常用来指基于Linux的完整操作系统，内核则称为Linux内核。目前Linux已被用于大多数大型主机和超级计算机，它也广泛应用在手机、平板电脑、路由器、电视等设备上。

### Ubuntu :

Ubuntu是以桌面应用为主的Linux发行版，也是目前最多用户的Linux版本。Ubuntu相当注重系统的易用性，也就是说，系统安装完成后，用户无需再费神安装浏览器、Office套装程序、多媒体播放程序等常用软件，一般也无需下载安装网卡、声卡等硬件设备的驱动（但部分显卡需要下载驱动程序）。

### CentOS :

CentOS是Linux的发行版之一，被用于一些要求高度稳定性的服务器。CentOS并不包含封闭源代码软件

### Android :

Android是一个基于Linux内核的开放源代码移动操作系统，使用Java和Kotlin作编程语言，主要设计用于触屏移动设备与其他便携式设备。

## 机器码、汇编语言、高级语言、脚本语言、编译器、运行库

### 机器码

机器语言指的是用二进制代码表示的计算机能直接识别和执行的一种机器指令的集合，它是计算机设计者通过计算机的硬件结构赋予计算机的操作功能，所以不同型号计算机的机器语言是不相通的。

其编码称为机器码（Machine Code）/原生码（Native
Code）。使用者大多为计算机/CPU生产厂家的专业人员，绝大多数程序员不会再去学机器语言；

因为在老式计算机中数据是按二进制储存的，所以就用了纸带打点的方式记录数据，这是非常麻烦的。

“1”代表纸带透光，光敏电阻阻值变小，输出电压升高，为高电平，“0”代表纸带不透光，光敏电阻阻值变大，输出电压变小，为低电平。

### 汇编语言

使用机器语言编写程序是一种相当烦琐的工作，既难于记忆也难于操作，编写出来的程序全是由0和1的数字组成，直观性差、难以阅读。不仅难学、难记、难检查、又缺乏通用性，给计算机的推广使用带来很大的障碍。

所以，人们想是不是可以开发出更加方便使用和理解的语言呢，这样就诞生了汇编语言。人们首先注意到的是可读性和可移植性，汇编语言可以对机器语言抽象表示，将机器语言的每一条指令符号化：指令码代之以记忆符号，地址码代之以符号地址，使得其含义显现在符号上而不再隐藏在编码中，可让人望"文"生义。

其次表现在这种语言摆脱了具体计算机的限制，可在不同指令集的计算机上运行，只要该计算机配上汇编语言的一个汇编程序。

### 高级语言

汇编程序的每一句指令只能对应实际操作过程中的一个很细微的动作，例如移动、自增，因此汇编源程序虽然比机器语言易于查看，但还是比较冗长、复杂、容易出错，而且使用汇编语言编程需要有更多的计算机专业知识。

于是，人们又想是不是可以更简单一点，于是就出现了高级语言，将许多相关的机器指令合成为单条指令并且去掉了与具体操作有关但与完成工作无关的细节，简化了程序中的指令。

现在常见的高级语言有C，C++，Java。

### 脚本语言

脚本语言是为了缩短传统的编译过程而创建的，需要一边执行一边翻译，但不会生成任何可执行文件，用户必须拿到源码才能运行程序。程序运行后会即时翻译，翻译完一部分执行一部分，不用等到所有代码都翻译完。

这个过程叫做解释，这样的编程语言叫做解释型语言或者脚本语言（Script），完成解释过程的软件叫做解释器。

常见的脚本语言有python，Java Script。

### 编译器

高级计算机语言便于人编写，阅读交流，维护。机器语言是计算机能直接解读、运行的。而编译器是将汇编或高级计算机语言源程序作为输入，翻译成目标语言机器代码的等价程序，将便于人理解的程序翻译成机器容易理解的程序。

编译器的一个极为重要的功能是对程序中错误的反应，几乎在编译的每个阶段都可以诊断出错误。在词法分析阶段会发现字符的拼写错误，在语法分析阶段会检查单词串是否违反语言的结构规则，语义分析中，编译器进一步检查语法上正确但无意义的操作成分。

### 运行库

官方解释是运行库是一个经过封装的程序模块，对外提供接口，只要知道接口参数就可以自由使用。如果不使用运行库，每个程序中都会包含很多重复的代码，而使用运行库，可以大大缩小编译后的程序的大小。但另一方面，由于使用了运行库，所以在分发程序时就必须带有这些库，比较麻烦。如果在操作系统中找不到相应的运行库程序就无法运行。

## MBR、GPT、BIOS、UEFI、FAT32、exFAT、NTFS

### MBR

MBR，即主引导记录，是对IBM兼容机的硬盘或者可移动磁盘分区时，在驱动器最前端的一段引导扇区。MBR概念是在1983年PC
DOS 2.0支持硬盘后才有的。

MBR描述了逻辑分区的信息，包含文件系统以及组织方式。此外，MBR还包含计算机在启动的第二阶段加载操作系统的可执行代码或连接每个分区的引导记录(VBR)。这个MBR代码通常被称为引导程序。

由于MBR分区表的最大可寻址的存储空间只有2Tb(2×512字节)。因此，在大硬盘出现的现在，MBR分区方式逐渐被GUID分区表取代。

MBR不可能存在于不可分区的媒介如软盘等中

### GPT

全局唯一标识分区表（GUID Partition
Table，缩写：GPT）是指全局唯一标示磁盘分区表格式。它是可扩展固件接口（EFI）标准（被Intel用于替代个人计算机的BIOS）的一部分，被用于替代BIOS系统中的以32bits来存储逻辑块地址和大小信息的主引导记录（MBR）分区表。

对于那些扇区为512字节的磁盘，MBR分区表不支持容量大于2.2TB（2.2
×10字节）的分区，然而，一些硬盘制造商（诸如希捷和西部数据）注意到这个局限性，并且将他们的容量较大的磁盘升级到4KB的扇区，这意味着MBR的有效容量上限提升到16
TiB。

截止至2010年，大多数操作系统对GPT均有所支持，尽管包括Mac OS
X和Windows在内的一些仅支持在EFI基础上自GPT分区启动。

### BIOS

BIOS是英文"Basic Input Output
System"的缩略词，直译过来后中文名称就是"基本输入输出系统"。其实，它是一组固化到计算机内主板上一个ROM芯片上的程序，它保存着计算机最重要的基本输入输出的程序、开机后自检程序和系统自启动程序，它可从CMOS中读写系统设置的具体信息。其主要功能是为计算机提供最底层的、最直接的硬件设置和控制。当今，此系统已成为一些病毒木马的目标。一旦此系统被破坏，其后果不堪设想。

BIOS设置程序是储存在BIOS芯片中的，BIOS芯片是主板上一块长方型或正方型芯
，只有在开机时才可以进行设置。CMOS主要用于存储BIOS设置程序所设置的参数与数据，而BIOS设置程序主要对计算机的基本输入输出系统进行管理和设置，使系统运行在最好状态下，使用BIOS设置程序还可以排除系统故障或者诊断系统问题。有人认为既然BIOS是"程序"，那它就应该是属于软件，感觉就像自己常用的Word或Excel。但也有很多人不这么认为，因为它与一般的软件还是有一些区别，而且它与硬件的联系也是相当地紧密。形象地说，BIOS应该是连接软件程序与硬件设备的一座"桥梁"，负责解决硬件的即时要求

### UEFI

新型UEFI，全称"统一的可扩展固件接口"(Unified Extensible Firmware Interface)，
是一种详细描述类型接口的标准。这种接口用于操作系统自动从预启动的操作环境，加载到一种操作系统上。

可扩展固件接口(Extensible Firmware Interface，EFI)是 Intel 为 PC
固件的体系结构、接口和服务提出的建议标准。其主要目的是为了提供一组在 OS
加载之前(启动前)在所有平台上一致的、正确指定的启动服务，被看做是有近20多年历史的
BIOS 的继任者。

UEFI是由EFI1.10为基础发展起来的，它的所有者已不再是Intel，而是一个称作Unified
EFI Form的国际组织。

BIOS即Basic Input/Output
System，翻成中文是"基本输入/输出系统"，是一种所谓的"固件"，负责在开机时做硬件启动和检测等工作，并且担任操作系统控制硬件时的中介角色。

因为硬件发展迅速，传统式(Legacy)BIOS
成为进步的包袱，现在已发展出最新的UEFI(Unified Extensible Firmware
Interface)可扩展固件接口，相比传统 BIOS 的来说，未来将是一个"没有特定
BIOS"的电脑时代。

与legacy BIOS 相比，UEFI最大的几个区别在于:

1\. 编码99%都是由C语言完成;

2\. 一改之前的中断、硬件端口操作的方法，而采用了Driver/protocol的新方式;

3\. 将不支持X86实模式，而直接采用Flat mode(也就是不能用DOS了，现在有些 EFI 或
UEFI 能用是因为做了兼容，但实际上这部分不属于UEFI的定义了);

4\. 输出也不再是单纯的二进制code，改为Removable Binary Drivers;

5\. OS启动不再是调用Int19，而是直接利用protocol/device Path;

6.
对于第三方的开发，前者基本上做不到，除非参与BIOS的设计，但是还要受到ROM的大小限制，而后者就便利多了。

7.弥补BIOS对新硬件的支持不足的问题。FAT32

即File Allocation Table
32。FAT32使每个簇变得更小，FAT32支持的磁盘容量达到2048GB，而FAT只能支持2GB的磁盘大小。FAT32使每个文件存放的空间变小，即达到了增大磁盘空间的目的。

### exFAT

exFAT(Extended File Allocation Table File
System，扩展FAT，也称作FAT64，即扩展文件分配表)是Microsoft在Windows Embeded
5.0以上(包括Windows CE 5.0、6.0、Windows
Mobile5、6、6.1)中引入的一种适合于闪存的文件系统，为了解决FAT32等不支持4G及其更大的文件而推出。对于闪存，NTFS文件系统不适合使用，exFAT更为适用。对于磁盘则不太适用。

### NTFS文件系统

NTFS (New Technology File System)，是 WindowsNT
环境的文件系统。新技术文件系统是Windows NT家族(如，Windows 2000、Windows
XP、Windows Vista、Windows 7和 windows
8.1)等的限制级专用的文件系统(操作系统所在的盘符的文件系统必须格式化为NTFS的文件系统，4096簇环境下)。NTFS取代了老式的FAT文件系统。

NTFS对FAT和HPFS作了若干改进，例如，支持元数据，并且使用了高级数据结构，以便于改善性能、可靠性和磁盘空间利用率，并提供了若干附加扩展功能。

该文件系统的详细定义属于商业秘密 ，微软已经将其注册为知识产权产品。

## 阿帕网、 CERNET2、 MAC地址、IP协议、IP地址、端口、ipv4、ipv6、IP报文头各部分作用、子网掩码、OSI模型

### 阿帕网

美国国防部高级研究计划局组建的计算机网。阿帕网于1968年开始组建 ，1969
年第一期工程投入使用，当时是一个军用研究系统。阿帕网是建立在“包交换理论”基础之上的一个去中心化的，或者叫做分布式的网络系统。所谓“包交换理论”就是把每个信息分割成固定大小块“打包”，每个包上都注明了从哪里来，传向哪里。

互联网包含因特网，因特网包含万维网，凡是能彼此通信的设备组成的网络就叫互联网。而最初的因特网就是阿帕网。

**CERNET2**

第二代中国教育和科研计算机网，是目前所知世界上规模最大的采用纯IPv6技术的下一代互联网主干网。

### MAC地址

在[OSI模型](https://baike.baidu.com/item/OSI%E6%A8%A1%E5%9E%8B)中，第三层[网络层](https://baike.baidu.com/item/%E7%BD%91%E7%BB%9C%E5%B1%82/4329439)负责
[IP地址](https://baike.baidu.com/item/IP%E5%9C%B0%E5%9D%80)，第二层数据链路层则负责
MAC地址。因此一个主机会有一个MAC地址，而每个网络位置会有一个专属于它的IP地址。

在运行中输入cmd，按回车。在命令提示附中输入ipconfig/all，便可以看到本机的IP地址mac地址等等一系列信息。

### IP协议

IP协议是用于将多个包交换网络连接起来的，它在源地址和目的地址之间传送一种称之为数据包的东西，它还提供对数据大小的重新组装功能，以适应不同网络对包大小的要求。

### IP地址

IP地址是指互联网协议地址。[Internet](https://baike.baidu.com/item/Internet)上的每台[主机](https://baike.baidu.com/item/%E4%B8%BB%E6%9C%BA)有一个唯一的IP[地址](https://baike.baidu.com/item/%E5%9C%B0%E5%9D%80)。[IP协议](https://baike.baidu.com/item/IP%E5%8D%8F%E8%AE%AE)就是使用这个地址在[主机](https://baike.baidu.com/item/%E4%B8%BB%E6%9C%BA)之间[传递](https://baike.baidu.com/item/%E4%BC%A0%E9%80%92)信息，这是Internet
能够运行的基础。IP地址可以视为网络标识号码与主机标识号码两部分，因此IP地址可分两部分组成，一部分为网络地址，另一部分为[主机地址](https://baike.baidu.com/item/%E4%B8%BB%E6%9C%BA%E5%9C%B0%E5%9D%80)。

Ipv4地址分为A、B、C、D、E5类，它们适用的类型分别为：大型网络；中型网络；小型网络；多目地址；备用。常用的是B和C两类。

IPv6的128位地址通常写成8组，每组为四个十六进制数的形式。比如：AD80:0000:0000:0000:ABAA:0000:00C2:0002
是一个合法的IPv6地址。
在某些情况下，一个IPv6地址中问可能包含很长的一段0，可以把连续的一段0压缩为“::”。但为保证地址解析的唯一性，地址中“::”只能出现一次。

[IP](https://baike.baidu.com/item/IP)地址就像是我们的家庭住址一样，如果你要写信给一个人，你就要知道他（她）的地址，这样邮递员才能把信送到。计算机发送信息就好比是邮递员，它必须知道唯一的“家庭地址”才能不至于把信送错人家。

### 端口

例如：TCP端口和UDP端口。计算机之间相互通信的时候，分为两种方式：一种是发送信息以后，可以确认信息是否到达，也就是有应答的方式，这种方式大多采用TCP协议；一种是发送以后就不管了，不去确认信息是否到达，这种方式大多采用UDP协议。对应这两种协议的服务提供的端口，也就分为TCP端口和UDP端口。

1.周知端口。周知端口是众所周知的端口号，范围从0到1023，其中80端口分配给WWW服务，21端口分配给FTP服务等。我们在IE的地址栏里输入一个网址的时候（
比如[www.cce.com.cn](http://www.cce.com.cn/)）是不必指定端口号的，因为在默认情况下WWW服务的端口号是“80”。网络服务是可以使用其他端口号的，如果不是默认的端口号则应该在地址栏上指定端口号，方法是在地址后面加上冒号“:”（半角），再加上端口
号。比如使用“8080”作为WWW服务的端口，则需要在地址栏里输入“www.cce.com.cn:8080”。但是有些系统协议使用固定的端口号，它是不能被改变的，比如139端口专门用于NetBIOS与TCP/IP之间的通信，不能手动改变。

2.动态端口。动态端口的范围是从1024到65535。之所以称为动态端口，是因为它一般不固定分配某种服务，而是动态分配。动态分配是指当一个系统进程或应用程序进程需要网络通信时，它向主机申请一个端口，主机从可用的端口号中分配一个供它使用。当这个进程关闭时，同时也就释放了所占用的端口号。

### ipv4，ipv6

都是互联网协议。IPv4中规定IP地址长度为32，即有2\^32-1个地址；而IPv6中IP地址的长度为128即有2\^128-1个地址。

### IP报文头各部分作用

IP数据包也叫IP报文分组，传输在ISO网络7层结构中的网络层，它由IP报文头和卡IP报文用户数据组成。其中报文头包含了从哪里来到哪里去的信息。

### 子网掩码

它是一种用来指明一个IP地址的哪些位标识的是主机所在的子网，以及哪些位标识的是主机的位掩码。

对于ipv4的A类地址来说，默认的子网掩码是255.0.0.0；对于B类地址来说默认的子网掩码是255.255.0.0；对于C类地址来说默认的子网掩码是255.255.255.0。

子网掩码运算例子：

I P 地址：192.168.0.1；子网掩码：255.255.255.0

转化为二进制进行运算：

I P 地址 11000000.10101000.00000000.00000001

子网掩码 11111111.11111111.11111111.00000000

AND运算后得：11000000.10101000.00000000.00000000

化为十进制：192.168.0.0

### OSI模型

OSI采用了分层的结构化技术，共分七层，物理层、数据链路层、网络层、传输层、会话层、表示层、应用层。OSI模型是开放系统互连参考模型，为开放式的互连信息提供一种功能的框架。举个栗子，你通过计算机向其他人传递某一个信息的时候，要保证信息正确准确的传递到他的计算机上，就要遵守一定的协议。否则，他的计算机可能就不能识别你的信息。

### TCP模型

TCP/IP是一组用于实现网络互连的通信协议。Internet网络体系结构以TCP/IP为核心。基于TCP/IP的参考模型将协议分成四个层次，它们分别是：网络访问层、网际互联层（主机到主机）、传输层、和应用层。

#### 共同点

（1）OSI参考模型和TCP/IP参考模型都采用了层次结构的概念。

（2）都能够提供面向连接和无连接两种通信服务机制。

#### 不同点

（1）OSI采用的七层模型，而TCP/IP是四层结构。

（2）TCP/IP参考模型的网络接口层实际上并没有真正的定义，只是一些概念性的描述。而OSI参考模型不仅分了两层，而且每一层的功能都很详尽，甚至在数据链路层又分出一个介质访问子层，专门解决局域网的共享介质问题。

（3）OSI模型是在协议开发前设计的，具有通用性。TCP/IP是先有协议集然后建立模型，不适用于非TCP/IP网络。

（4）OSI参考模型与TCP/IP参考模型的传输层功能基本相似，都是负责为用户提供真正的端对端的通信服务，也对高层屏蔽了底层网络的实现细节。所不同的是TCP/IP参考模型的传输层是建立在网络互联层基础之上的，而网络互联层只提供无连接的网络服务，所以面向连接的功能完全在TCP协议中实现，当然TCP/IP的传输层还提供无连接的服务，如UDP；相反OSI参考模型的传输层是建立在网络层基础之上的，网络层既提供面向连接的服务，又提供无连接的服务，但传输层只提供面向连接的服务。

（5）OSI参考模型的抽象能力高，适合与描述各种网络；而TCP/IP是先有了协议，才制定TCP/IP模型的。

（6）OSI参考模型的概念划分清晰，但过于复杂；而TCP/IP参考模型在服务、接口和协议的
区别上不清楚，功能描述和实现细节混在一起。

（7）TCP/IP参考模型的网络接口层并不是真正的一层；OSI参考模型的缺点是层次过多，划分意义不大但增加了复杂性。

（8）OSI参考模型虽然被看好，由于没把握好时机，技术不成熟，实现困难；相反，TCP/IP参考模型虽然有许多不尽人意的地方，但还是比较成功的。

## BT、TCP、UDP、域名、DNS、DNS污染

### BT

BT是BitTorrent协议的简称。BitTorrent协议由美国的布拉姆·科恩(Bram
Cohen)发明，不同于传统的由一个服务器向多个客户发送数据的形式，BT开创了新的形式：用户使用BT软件下载资源的同时也在上传资源给其他下载的用户。当使用BT协议下载文件时，对于同一个文件，用户下载它的来源可以是任何一个拥有此资源的其他用户而不局限于同一个服务器，对于不同的部分从不同来源下载，因此有效地提高了下载速度。

### TCP

TCP即：Transmission Control Protocol
传输控制协议。TCP层是位于IP层之上，应用层之下的中间层。应用层向TCP层发送用于网络间传输的、用8位字节表示的数据流，然后TCP把数据流分区成适当长度的报文段。之后TCP把结果包传给IP层，由它来通过网络将包传送给接收端实体的TCP层。

TCP为了保证不发生丢包，就给每个包一个序号，同时序号也保证了传送到接收端实体的包的按序接收。然后接收端实体对已成功收到的包发回一个相应的确认。如果发送端实体在合理的往返时延内未收到确认，那么对应的数据包就被假设为已丢失，将会被进行重传。

### UDP

UDP即：User Data Protocol
用户数据报协议。是与TCP相对应的协议。它是面向非连接的协议，它不与对方建立连接，而是直接把数据包发送过去。

UDP适用于一次只传送少量数据、对可靠性要求不高的应用环境。
“ping”命令的原理就是向对方主机发送UDP数据包，然后对方主机确认收到数据包，如果数据包是否到达的消息及时反馈回来，那么网络就是通的。因为UDP协议没有连接的过程，所以它的通信效果高；但是它的可靠性不如TCP协议高。

### 域名

域名（Domain
Name），简称域名、网域。是由一串用点分隔的名字组成的Internet上某一台计算机或计算机组的名称，用于在数据传输时标识计算机的电子方位（有时也指地理位置）。

常见的域名后缀及其含义有：

.com：国际通用顶级域名，也是目前使用最为广泛的域名；

.net：国际通用域名，也是目前国际广泛流行的域名，后缀代表网络服务机构；

.cn：中国国家级顶级域名，也是在国内广泛使用的域名，后缀表示含义为中国企业互联网标识；

.org：国际顶级域名，是目前国际广泛使用的域名，后缀含义代表是非盈利性组织；

.edu：教育机构(education)的域名；

.gov：政府(government)的域名；

### DNS

DNS即：Domain Name System
域名系统。万维网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便的访问互联网，而不用去记忆某个难记的IP地址。

### DNS污染

DNS污染是指一些刻意制造或无意中制造出来的域名服务器分组，把域名指往不正确的IP地址。

# 计算机硬件概念：

### 物理核心

每颗物理CPU可以有1个或者多个物理内核，通常每颗物理CPU的内核数都是固定的，单核CPU就是有1个物理内核，双核CPU就是有2个物理内核。

在Linux上查看/proc/cpuinfo，其中的core
id就是每颗物理CPU的物理内核id，有几个不同的core id就有几个物理内核。

总的CPU物理内核数 = 物理CPU数 \* 每颗物理CPU的内核数

### 逻辑核心

操作系统可以使用逻辑CPU来模拟真实CPU。在没有多核处理器的时候，一个物理CPU只能有一个物理内核，而现在有了多核技术，一个物理CPU可以有多个物理内核，可以把一个CPU当作多个CPU使用，也就是所谓的逻辑CPU。

没有开启超线程时，逻辑CPU的个数就是总的CPU物理内核数。然而开启超线程后，逻辑CPU的个数就是总的CPU物理内核数的两倍。

在Linux上查看/proc/cpuinfo，其中的processor就是逻辑CPU，有几个processor就有几个逻辑CPU。

总的逻辑CPU数 = 物理CPU个数 \* 每颗物理CPU的核数 \* 超线程数

总的逻辑CPU数 = 总的CPU物理内核数 \* 超线程数

### 进程

进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动,进程是系统进行资源分配和调度的一个独立单位.

### 线程

线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源.

## CPU架构与指令集、CPU流水线、制程

### CPU架构与指令集：

CPU架构CPU厂商给属于同一系列的CPU产品定的一个规范，主要目的是为了区分不同类型CPU的重要标示。目前市面上的CPU分类主要分有两大阵营，一个是intel、AMD为首的复杂指令集CPU，另一个是以IBM、ARM为首的精简指令集CPU。两个不同品牌的CPU，其产品的架构也不相同，例如，Intel、AMD的CPU是X86架构的，而IBM公司的CPU是PowerPC架构，ARM公司是ARM架构。

CPU架构与指令集相对应。每种CPU架构都有其特定对应的指令集。

指令集是存储在CPU内部，对CPU运算进行指导和优化的硬程序。主要有RISC（精简指令集）和CISC（复杂指令集）两种指令集。CISC通过设置一些功能复杂的指令，把一些原来由软件实现的、常用的功能改用硬件的指令系统实现，以此来提高计算机的执行速度。RISC只保留那些功能简单、能在一个节拍内执行完成的指令，而把较复杂的功能用一段子程序来实现。

RISC下有POWERPC和ARM等。CISC下有x86，x86-64等X86指令集是美国Intel公司为其第一块16位CPU(i8086)专门开发的，美国IBM公司1981年推出的世界第一台PC机中的CPU--i8088(i8086简化版)使用的也是X86指令，同时电脑中为提高浮点数据处理能力而增加的X87芯片系列数学协作处理器则另外使用X87指令，以后就将X86指令集和X87指令集统称为X86指令集。

2003年，AMD推出了业界首款64位处理器Athlon
64，也带来了x86-64，即x86指令集的64位扩展超集，具备向下兼容的特点

POWERPC是1991年，Apple、IBM、Motorola组成的AIM联盟所发展出的微处理器架构（现在基本凉透了)。最初苹果电脑均使用该架构的CPU，但苹果电脑自2005年起，将旗下电脑产品转用Intel
CPU。

### CPU流水线：

CPU流水线技术是一种将指令分解为多步，并让不同指令的各步操作重叠，从而实现几条指令并行处理，以加速程序运行过程的技术。

借鉴了工业流水线制造的思想，现代CPU也采用了流水线设计。在工业制造中采用流水线可以提高单位时间的生产量；同样在CPU中采用流水线设计也有助于提高CPU的频率。

采用流水线技术后，并没有加速单条指令的执行，每条指令的操作步骤一个也不能少，只是多条指令的不同操作步骤同时执行，因而从总体上看加快了至零六速度，缩短了程序执行时间。

### 制程：

根据ITRS《国际半导体技术蓝图》里面的相关规定，我们平常说说的16nm、14nm、10nm就是用来描述半导体制程I艺的节点代数，而它应在不同半导体元件上,所描述的对象可能有所不一样。总的来说，xxnm制程描述了该工艺代下加工尺度的精确度，但它并非指半导体器件中某一具体结构的特征尺时，而是加工精度的尺寸的最小值。这里我们主要讨论的是关于CPU的制程问题，因为制程对于CPU性能、功耗、发热来说有着比较重要地位，制程的改变对于CPU性能的影响也是非常之大的。14nm通常就是用来描述晶体管的栅极线宽。

当其是指栅极宽度（沟道长度）时，图中的晶体管结构中，电流从 Source(源极)流入
Drain(漏级)，Gate(栅极)相当于闸门，主要负责控制两端源极和漏级的通断。电流会损耗，而栅极的宽度则决定了电流通过时的损耗，表现出来就是手机常见的发热和功耗，宽度越窄，功耗越低。而栅极的最小宽度(栅长)，就是
XX nm工艺中的数值。

## 串行、并行总线的区别及其优劣，驱动，操作系统

### 串行总线：

在远程通信和计算机科学中，串行通信是指在计算机总线或其他数据通道上，每次传输一个位元数据，并连续进行以上单次过程的通信方式。与之对应的是并行通信，它在串行端口上通过一次同时传输若干位元数据的方式进行通信。串行通信被用于长距离通信以及大多数计算机网络，在这些应用场合里，电缆和同步化使并行通信实际应用面临困难。凭借着其改善的信号完整性和传播速度，串行通信总线正在变得越来越普遍。

### 并行总线：

并行是指“并排行走”或“同时实行或实施”。在操作系统中是指，一组程序按独立异步的速度执行，不等于时间上的重叠（同一个时刻发生)。要区别并发。并发是指：在同一个时间段内，两个或多个程序执行，有时间上的重叠（宏观上是同时，微观上仍是顺序执行）。并行也指以计算机的字长，通常是8位、16位或32位为传输单位同时通过并行线进行传送。

### 串行总线

#### **优点：**

1.
采用串行总线以后，就单根线来说，由于上面要传输原来多根线传输的数据，所以其工作速率一般要比相应的并行总线高很多。

2.
采用串行总线的另一个好处是提高数据传输速率的同时节省了布线空间，同时芯片的功耗也降低了。

3.
使用串行总线的设备的体积、功耗和数据传输速度都比使用并行接口的设备更有优势，因此得到了广泛的应用。

4.
串行总线的信号线只有一根（或两根），没有串扰（或不明显），所以传输频率可以进一步提高，足够可以将传输速度超过并行通讯。

#### **缺点：**

数据速率提高以后，对于阻抗匹配、线路损耗和抖动的要求就更高，稍不注意就很容易产生信号质量的问题。

### 并行总线

#### **优点：**

1\. 电路的逻辑时序比较简单，实现起来比较容易。

2\. 在相同频率下,并口传输的效率是串口的几倍。

#### **缺点：**

1.
随着传输频率的提高，并行传输线中信号线与信号线之间的串扰越加明显，所以这也制约了并行通讯传输频率的提高（达到100MHz已经是很难了）。

2.信号线多，会占大量的管脚和空间，所以芯片和PCB板的尺寸很那实现小型化，所以远距离传输时，电缆就会变得非常昂贵和笨重。

### 驱动：

驱动程序即添加到操作系统中的一小块代码，其中包含有关硬件设备的信息。有了此信息，计算机就可以与设备进行通信。驱动程序是硬件厂商根据操作系统编写的配置文件，可以说没有驱动程序，计算机中的硬件就无法工作。操作系统不同，硬件的驱动程序也不同，各个硬件厂商为了保证硬件的兼容性及增强硬件的功能会不断地升级驱动程序。

### 操作系统：

操作系统（Operating
System，简称OS）是管理和控制计算机硬件与软件资源的计算机程序，是直接运行在“裸机”上的最基本的系统软件，任何其他软件都必须在操作系统的支持下才能运行。

操作系统是用户和计算机的接口，同时也是计算机硬件和其他软件的接口。操作系统的功能包括管理计算机系统的硬件、软件及数据资源，控制程序运行，改善人机界面，为其它应用软件提供支持，让计算机系统所有资源最大限度地发挥作用，提供各种形式的用户界面，使用户有一个好的工作环境，为其它软件的开发提供必要的服务和相应的接口等。

## RAM、ROM、SRAM、DRAM、DDR SDRAM、FLASH介绍

### RAM

随机存取存储器，也叫主存，是与CPU直接交换数据的内部存储器。它可以随时读写（刷新时除外），而且速度很快，通常作为操作系统或其他正在运行中的程序的临时数据储存媒介。

当电源关闭时，RAM不能保留数据。现代的随机存取存储器几乎是所有访问设备中写入和读取速度最快的，访问延迟和其他涉及机械运作的储存设备相比，也显得微不足道。但速度仍然不如作为CPU缓存用的SRAM。

### ROM

只读存储器是一种半导体存储器，其特性是一旦存储数据就无法再将之改变或删除，且内容不会因为电源关闭而消失。在电子或电脑系统中，通常用以存储不需经常变更的程序或数据，例如早期的家用电脑如Apple
II的监督程序、BASIC语言解释器、硬件点阵字体、个人电脑的BIOS等。

### DRAM

动态随机存取存储器是一种半导体存储器，主要的作用原理是利用带内容内存储电荷的多寡来表示一个二进制bit是0还是1.由于在现实中晶体管会有漏电电流的现象，导致电容上所存储的点和数量并不足以正确的判断数据，而导致数据损毁，因此DRAM就需要周期性的充电。由于这种需要定时刷新的特性，因此被称为“动态”存储器。相比于SRAM，DRAM拥有非常高的晶体管密度，单位体积的容量较高因此成本较低。但相反，DRAM的访问速度较慢，耗电量也较大。

### SRAM

静态随机存取存储器是随机存取存储器的一种。所谓“静态”，是指这种存储器只要保持通电里面储存的数据就可以恒常保持。相对之下，DRAM里面所储存的数据就需要周期性地更新。然而，当电力供应停止时，SRAM储存的数据还是会消失。

### DDR SDRAM

双倍数据率同步动态随机存取存储器，为具有双倍数据传输率的SDRAM，其数据传输速度为系统时钟频率的两倍，由于速度增加，其传输性能优于传统的SDRAM。

### FLASH

快闪存储器，是一种电子式可清除程序化只读存储器的形式，允许在操作中被多次擦或写的存储器。这种科技主要用于一般性数据存储，以及在电脑与其他数字产品间交换传输数据，如储存卡和U盘。早期的闪存进行一次抹除，就会清除掉整颗芯片上的数据。

单就保存数据而言，它是不需要消耗电力的。与硬盘相比，闪存有更佳的动态抗震性。当它被制成储存卡时非常可靠，即使浸在水中也足以抵抗高压与极端的温度。闪存的写入速度往往明显慢于读取速度。

## 台湾清华大学、新竹科技园、台积电、联发科、光刻机

### 台湾清华大学

台湾清华大学前身为1911年在北京设立的清华学堂。1925年设大学部。对日抗战期间，西迁至云南昆明，与国立北京大学、私立南开大学合组国立西南联合大学。国共内战后，清华大学被分成两个，北京的清华大学由中华人民共和国政府接管，而台湾当局则于1955年于台湾省新竹市让清华大学复校，复校之初首设原子科学研究所，1964年恢复大学部。

上世纪70年代，新竹科技产业园吸收了台湾清华大学、交通大学的人才研究资源，在政府的主导下与RCA开展了晶圆制造项目的合作。

在此之后，逐渐所有的台湾大学都开始大幅度将学生输送到欧美日发达国家进行培养，将台湾大学、成功大学、交通大学、清华大学等大学培养成知名的学府。

### 新竹科技园

新竹科技园区是台湾第一个科技园，号称台湾硅谷。经过20多年的发展，新竹科技园现在的开发面积是6.32平方公里，成为孕育台湾高技术产业发展的基地，其IC产业更是台湾发展高技术产业成功的典范。下面所说的台湾积体电路制造股份有限公司与中国台湾联发科技股份有限公司均位于台湾新竹科技园区。

由于历史原因，从上世纪70年代开始台湾在外交、经济方面遭遇危机，于是当时新任经济部长孙运璿便决心开启工业技术转型。

“我们如果再不做，就赶不上了，”孙运璿曾这么评价当时台湾的状况。随后便将分散在各处的联合工业研究所、联合矿业研究所与金属工业研究所合并，成立“工业技术研究院”。与美国无线电公司
(Radio Corporation of America,
RCA)取得合作，将相关人才派驻过去学习，这些人才成为了现在国际半导体行业里的大佬。

等这一批从大学、相关部门挑选出的人才学成归来，台湾便建立起了世界上第一个由政府主导成立的科技产业园区——新竹科技产业园。新竹科技产业园吸收了台湾清华大学、交通大学的人才研究资源，在政府的主导下与RCA开展了晶圆制造项目的合作。

### 台积电

台湾积体电路制造股份有限公司，简称台积电、TSMC，属于半导体制造公司。成立于1987年，是全球第一家专业积体电路制造服务（晶圆代工foundry）企业，总部与主要工厂位于台湾新竹科学园区。

1987年，张忠谋创立台积电，开创了晶圆代工（foundry）模式。

晶圆代工，半导体产业的一种营运模式，专门从事半导体晶圆制造生产，接受其他IC设计公司委托制造，而不自己从事设计的公司。有些拥有晶圆厂的半导体公司，如英特尔(Intel)、AMD等，会因产能或成本等因素，也会将部份产品委由晶圆代工公司生产制造。台积电、联电为世界排名第一与第二的晶圆代工公司。反之，专门从事IC电路设计而不从事生产且无半导体厂房的公司称为无厂半导体公司(Fabless)。无厂半导体公司依赖晶圆代工公司生产产品，因此产能、技术都受限于晶圆代工公司，但优点是不必自己兴建、营运晶圆厂。随着芯片制成微缩、晶圆尺寸成长，建设一间晶圆厂动辄百亿美金的经费，往往不是一般中小型公司所能够负担得起;而透过此模式与晶圆代工厂合作，IC设计公司就不必负担高阶制程高额的研发与兴建费用，晶圆代工厂能够专注于制造，开出的产能也可售予多个用户，将市场波动、产能供需失衡的风险减到最小。

### 联发科

中国台湾联发科技股份有限公司（MediaTek.Inc）是全球著名IC（集成电路）设计厂商（无晶圆厂模式公司又称为IC设计商，指那些仅从事晶圆，既芯片的设计、研发、应用和销售，而将晶圆制造外包给专业的晶圆代工厂的半导体公司），专注于无线通讯及数字多媒体等技术领域。其提供的芯片整合系统解决方案，包含无线通讯、高清数字电视、光储存、DVD及蓝光等相关产品。

目前，全球拥有研发或制造移动级处理器芯片的大厂一共有五家，分别是美国的高通、苹果、韩国的三星、我国的海思以及联发科。

要说联发科在芯片界的发展史，得需要从 2003 年开始说起。

2003
年，“山寨机”开始在手机市场上出现，联发科作为当时唯一获得移动处理器芯片制造技术的国内厂商推出了第一款手机解决方案，成为了不少“山寨机”厂商的首选。而“MTK”这个名字也陆续开始出现在各种“八个喇叭”、“多卡多待机”的山寨手机当中。

在深圳华强北手机市场的助推下，山寨机和 MTK
平台迅速占据了国内的不少手机市场份额。在之后的数年，市面上除了运行 Java、Symbian
平台的手机，还有采用 MTK 平台的手机。

而在这些山寨手机的背后，MTK
平台功不可没，这也是为联发科在未来的发展奠定了一个厚实的基础和资本。而在国内手机行业迅速发展后的数年里，MTK
平台以及衍生品被陆续运用在国产品牌的设备里，直到今天。

眨眼到 2011
年，智能手机已经成为了主流，山寨机、功能机逐渐退出市场，而联发科也开始从提供平台解决方案转型到移动处理器的制造行业中。

### 光刻机

光刻机（Mask Aligner)又名：掩模对准曝光机，曝光系统，光刻系统等。

光刻机是芯片制造的核心设备之一，按照用途可以分为好几种：有用于生产芯片的光刻机；有用于封装的光刻机；还有用于LED制造领域的投影光刻机。用于生产芯片的光刻机是中国在半导体设备制造上最大的短板，国内晶圆厂所需的高端光刻机完全依赖进口。

## PCI-E,SATA,SO-DIMM,M.2,NVMe,HDMI,VGA

### PCI-E:

PCI Express是新一代的总线接口。

它采用了目前业内流行的点对点串行连接，比起PCI以及更早期的计算机总线的共享并行架构，每个设备都有自己的专用连接，不需要向整个总线请求带宽，而且可以把[数据传率](https://baike.baidu.com/item/%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E7%8E%87/603683)提高到一个很高的频率，达到PCI所不能提供的高带宽。

### SATA:

SATA（Serial Advanced Technology
Attachment，串行高级技术附件）是一种基于行业标准的串行硬件驱动器接口，是由Intel、IBM、Dell、APT、Maxtor和Seagate公司共同提出的硬盘接口规范。2001年，由Intel、APT、Dell、IBM、希捷、迈拓这几大厂商组成的Serial
ATA委员会正式确立了Serial ATA 1.0规范，在当年的IDF Fall
大会上，Seagate宣布了Serial ATA 1.0标准，正式宣告了SATA规范的确立。

### SO-DIMM:

SO-DIMM (Small Outline Dual In-line Memory Module) ：
这是一种改良型的DIMM模块，比一般的DIMM模块来得小，应用于笔记型计算机、列表机、传真机或是各种[终端机](https://baike.baidu.com/item/%E7%BB%88%E7%AB%AF%E6%9C%BA/7163369)等。

SO-DIMM，中文含意为“小外形双列内存模组”，它是一种类型的计算机内存模组。相对于DIMM来说，SO-DIMM具有更小的外形尺寸（大致是正常DIMM尺寸的一半）。因此，SO-DIMM主要用于笔记本电脑等一些对尺寸有较高要求的使用场合。SO-DIMM具有72管脚（支持32位数据传输）或144管脚或200管脚（支持64位数据传输）。

### M.2接口:

Intel推出的一种替代MSATA新的接口规范。

与MSATA相比，M.2主要有两个方面的优势。第一是速度方面的优势。M.2接口有两种类型：Socket
2（B key——ngff）和Socket 3（M key——nvme），其中Socket2支持SATA、PCI-E
X2接口，而如果采用PCI-E
×2接口标准，最大的读取速度可以达到700MB/s，写入也能达到550MB/s。而其中的Socket
3可支持PCI-E ×4接口，理论带宽可达4GB/s。

第二个是体积方面的优势。虽然，MSATA的固态硬盘体积已经足够小了，但相比M.2接口的固态硬盘，MSATA仍然没有任何优势可言。M.2标准的SSD同mSATA一样可以进行单面NAND闪存颗粒的布置，也可以进行双面布置，其中单面布置的总厚度仅有2.75mm，而双面布置的厚度也仅为3.85mm。而mSATA在体积上的劣势就明显的多，51mm×30mm的尺寸让mSATA在面积上不占优势，而4.85mm的单面布置厚度跟M.2比起来也显得厚了太多。另外，即使在大小相同的情况下，M.2也可以提供更高的存储容量。

### NVM Express（NVMe）:

或称非易失性内存主机控制器接口规范(Non-Volatile Memory
express),，是一个逻辑设备接口规范。他是与AHCI类似的、基于设备逻辑接口的总线传输协议规范（相当于通讯协议中的应用层），用于访问通过PCI-Express（PCIe）总线附加的非易失性内存介质，虽然理论上不一定要求
PCIe 总线协议。

此规范目的在于充分利用PCI-E通道的低延时以及并行性，还有当代处理器、平台与应用的并行性，在可控制的存储成本下，极大的提升固态硬盘的读写性能，降低由于[AHCI](https://baike.baidu.com/item/AHCI)接口带来的高延时，彻底解放SATA时代固态硬盘的极致性能。

### HDMI: 

HDMI是（High Definition Multimedia
Interface）的缩写，意思是高清晰度多媒体接口，是一种数字化视频/音频接口技术，适合影像传输的专用型数字化接口，可同时传送[音频](https://baike.baidu.com/item/%E9%9F%B3%E9%A2%91/1197465)和影像信号，最高数据传输速度为48Gbps（2.1版）。

同时无需在信号传送前进行数/模或者模/数转换。HDMI可搭配宽带数字内容保护（HDCP），以防止具有著作权的影音内容遭到未经授权的复制。

HDMI所具备的额外空间可应用在日后升级的音视频格式中。

而因为一个1080p的视频和一个8声道的音频信号需求少于0.5GB/s，因此[HDMI](https://baike.baidu.com/item/HDMI)还有很大余量。这允许它可以用一个电缆分别连接DVD播放器，接收器和PRR

### VGA:

VGA（Video Graphics Array）即视频图形阵列，是IBM在1987年随PS/2（PS/2
原是“Personal System
2”的意思，“个人系统2”，是IBM公司在1987年推出的一种个人电脑。PS/2电脑上使用的键盘鼠标接口就是现在的PS/2接口。因为标准不开放，PS/2电脑在市场中失败了。只有PS/2接口一直沿用到今天）一起推出的使用模拟信号的一种视频传输标准，在当时具有分辨率高、显示速率快、颜色丰富等优点，在彩色显示器领域得到了广泛的应用。这个标准对于现今的个人电脑市场已经十分过时。即使如此，VGA仍然是最多制造商所共同支持的一个标准，个人电脑在加载自己的独特驱动程序之前，都必须支持VGA的标准。例如，微软Windows系列产品的开机画面仍然使用VGA显示模式，这也说明其在显示标准中的重要性和兼容性。

VGA最早指的是显示器640X480这种显示模式。

VGA技术的应用还主要基于VGA显示卡的计算机、笔记本等设备，而在一些既要求显示彩色高分辨率图像又没有必要使用计算机的设备上，VGA技术的应用却很少见到。

对于一些嵌入式VGA显示系统，可以在不使用VGA显示卡和计算机的情况下，实现VGA图像的显示和控制。系统具有成本低、结构简单、应用灵活的优点，可广泛应用于超市、车站、飞机场等公共场所的广告宣传和提示信息显示，也可应用于工厂车间生产过程中的操作信息显示，还能以多媒体形式应用于日常生活。

## 核显，GPU，流处理器，显卡架构

### 核显

核显即“核芯显卡”，是指GPU部分它是与CPU建立在同一内核芯片上，两者完全融合的芯片。

早期的集成显卡（Integrated
graphics）是指集成在主板上的图形处理单元，而核芯显卡是建立在和处理器同一内核芯片上的图形处理单元，算是集成显卡的一种，主要用于Intel
Core处理器中，因为原来的集显一般是集成在北桥（North Bridge）中，从Intel
Core时代开始，Intel将集成显卡整合到了CPU中，第一代的Lynnfield架构中整合显卡与CPU单元还是分离的，从第二代Sandy
Bridge开始整合的GPU单元已经成为CPU的一部分，因此Intel认为集成显卡的说法已经不能代表当前的状态，并将旗下的HD
Graphics集成显卡称为核显，相对应的CPU则被称为核芯。Lynnfield时代Intel开始把显卡整合到CPU中，Sandy
Bridge开始GPU与CPU不再独立，成为整体。

核显并不仅仅是命名上的变化，CPU和GPU单元整合到一起之后可以互相协同工作，比如Sandy
Bridge中新增了Quick
Sync快速转码单元，该电路位于GPU核心中，但是作用是为辅助CPU加速视频转码，测试显示开启Quick
Sync转码加速之后速度大幅提升，同时画质也要比独显的GPU加速方案更高。简而言之，就是与处理器核心合并在一起的图形处理器，使用内存充当显存。这种整合设计大大缩减了处理核心、图形核心、内存及内存控制器间的数据周转时间，有效提升处理效能并大幅降低芯片组整体功耗，有助于缩小了核心组件的尺寸，为笔记本、一体机等产品的设计提供了更强的性能、更丰富的多体能力以及更宽广的设计空间

相对于独立显卡，核芯显卡最主要的优势就是低功耗。核芯显卡采用精简架构和整合设计，使其对整体功耗的控制更加优异。但不足之处在于其性能只相当于低端独立显卡，一般并不适合玩大型游戏或进行复杂图像处理。

### GPU

GPU(Graphics Processing
Unit)中文翻译为图形处理器，又称显示核心，是一种专门进行图像运算工作的微处理器。

GPU的用途是将计算机系统所需要的显示信息进行转换驱动，并向显示器提供行扫描信号，控制显示器的正确显示，是连接显示器和个人电脑主板的重要元件，也是“人机对话”的重要设备之一。显卡作为电脑主机里的一个重要组成部分，承担输出显示图形的任务，对于从事专业图形设计的人来说显卡非常重要。

与CPU相比，GPU所进行的计算任务比较简单和单调，但计算量很大，因此，GPU内有更大规模的计算机构。如果把CPU比作一个大学生，可以进行复杂的计算任务，那么GPU就相当于一群小学生。进行图像处理，就相当于进行100次简单的加减法，显然一群小学生更适合干这种事情。

GPU可以集成在独立的显卡上，也可以集成在主板上（集显），也可以集成在CPU里（核显）。

### 流处理器

流处理器（Streaming Processor）是GPU内部的重要组成部分。

在DX10显卡出来以前，并没有“流处理器”这个说法。GPU内部由“管线”构成，分为像素管线和顶点管线，它们的数目是固定的。简单来说，顶点管线主要负责3D建模，像素管线负责3D渲染。由于它们的数量是固定的，这就出现了一个问题，当某个游戏场景需要大量的3D建模而不需要太多的像素处理，就会造成顶点管线资源紧张而像素管线大量闲置，当然也有截然相反的另一种情况。

在这样的情况下，人们在DX10时代首次提出了“统一渲染架构”，显卡取消了传统的“像素管线”和“顶点管线”，统一改为流处理器单元，它既可以进行顶点运算也可以进行像素运算，这样在不同的场景中，显卡就可以动态地分配进行定点运算和像素运算的流处理器数量，达到资源的充分利用；现在，流处理器的数量的多少已经成为了决定显卡性能高低的一个很重要的指标，Nvidia和AMD-ATI也在不断地增加显卡的流处理器数量使显卡的性能达到跳跃式增长，值得一提的是，N卡和A卡GPU架构并不一样，对于流处理器数的分配也不一样。

### 显卡架构

显卡架构指的是显卡内部的电路组成、结构、工作原理等遵循的标准。为了提升显卡工作性能，显卡的架构是在不断升级和更新换代的。

比如，早期GPU的规格主要用管线（Shader，着色器）来形容，分为像素管线（Pixel
Shader）和顶点管线（Vertex Shader）。被称“为分离式架构“。但因为资源分配不平衡
大量资源被浪费所以出现了“统一渲染架构”，即以流处理器单元代替这两个管线。

显卡生产厂商也在不断研发和推出新的架构，升级内部单元数量，增强参数等。

以下是英伟达历代显卡的架构名称：

Geforce系列 丨 核心代号(Code/Architecture） 丨代号简称（Abbreviation）  
100系列 丨（无具体科学家名称） 丨 G9x（x代表数字）  
200\~300系列 丨 特斯拉 （Tesla） 丨 GT  
400\~500系列 丨 费米（Fermi） 丨 GF  
600系列 丨开普勒（Kepler） 丨GK  
700\~900系列 丨麦克斯韦（Maxwell） 丨GM  
10系列 丨帕斯卡（Pascal） 丨GP  
（未来） 丨伏特（Volta） 丨GV

### LED屏幕

LED显示器（LED
panel），是一种通过控制半导体发光二极管的显示方式，用来显示文字、图形、图像、动画、行情、视频、录像信号等各种信息的显示屏幕。

通过发光二极管芯片的适当连接（包括串联和并联）和适当的光学结构。可构成发光显示器的发光段或发光点。由这些发光段或发光点可以组成数码管、符号管、米字管、矩阵管、电平显示器管等等。通常把数码管、符号管、米字管共称笔画显示器，而把笔画显示器和矩阵管统称为字符显示器。

### IPS

IPS屏幕就是基于TFT的一种技术，其实质还是TFT屏幕。IPS屏幕（In-Plane
Switching，平面转换）技术是日立公司于2001推出的液晶面板技术，俗称“Super TFT”。

硬屏就是表面附着了一层树脂的膜，如同人带眼镜一样。IPS硬屏之所以具有清晰超稳的动态显示效果，取决于其创新性的水平转换分子排列，改变了VA软屏垂直的分子排列，因而具有更加坚固稳定的液晶结构。并非表面意义上的，硬屏就是在液晶面板上加上一层硬的保护膜，为了避免液晶屏幕受外界硬物的戳伤。

### NTSC

NTSC制式，又简称为N制，是1952年12月由美国国家电视系统委员会（National Television
System
Committee，缩写为NTSC）制定的彩色电视广播标准，两大主要分支是NTSC-J（日本标准）与NTSC-US（又名NTSC-U/C，美国、加拿大标准）。

它属于同时制，每秒60/1.001场，扫描线为525，隔行扫描，水平分辨率相当于330，画面比例为4：3。

这种制式的色度信号调制包括了平衡调制和正交调制两种，解决了彩色黑白电视广播兼容问题，但存在相位容易有损、色彩不太稳定的缺点，故有人戏称NTSC为Never
The Same Color或Never Twice the Same Color（不会重现一样的色彩）。

### RGB

三原色光模式（RGB color
model），又称RGB颜色模型或红绿蓝颜色模型，是一种加色模型，将红（Red）、绿（Green）、蓝（Blue）三原色的色光以不同的比例相加，以合成产生各种色彩光。

RGB是一种依赖于设备的颜色空间：不同设备对特定RGB值的检测和重现都不一样，因为颜色物质（荧光剂或者染料）和它们对红、绿和蓝的单独响应水平随着制造商的不同而不同，甚至是同样的设备不同的时间也不同。

### G-Sync

G-SYNC技术可解决V-SYNC带来的取舍问题，不论画面更新率有多快，它都可以让屏幕与GPU完全同步，提供无与伦比的PC游戏体验。通过NVIDIA
G-SYNC技术游戏场景可即时呈现在玩家的眼前，物件也将更清晰锐利，游戏也变得更流畅。

### 可视角

显示器可视角度指的是使用者能从不一样的方位清晰地看见荧幕上所有显示内容的角度，可视角度包括水平可视角度与垂直可视角度这两个标准。水平可视角度意思是靠荧幕的垂直法线做基准，在垂直于法线左边或者右边一定角度的方位上还可以正常的观察到用户认可的图像，此角度范围就为液晶水平可视角度；一个道理假如用水平法线为基准，上下可视角度就被叫做垂直可视角度。

因为提供LCD荧幕的光源经折射与反射之后输出的时候早已有了一定的方向性，如果超过这个范围内观察就会发生色彩失真情况，CRT显示器不会有这个问题，所以CRT显示器可视角度一般优于液晶显示器[1]。IPS液晶为目前市面上可视角度最广的液晶。

### 对比度

对比度是画面黑与白的比值，也就是从黑到白的渐变层次。比值越大，从黑到白的渐变层次就越多，从而色彩表现越丰富。对比度对视觉效果的影响非常关键，一般来说对比度越大，图案越清晰醒目，色彩也越鲜明艳丽；而对比度小，则会让整个画面都灰蒙蒙的。

高对比度对于图片的清晰度、细节表现、灰度层次表现都有很大帮助。在一些黑白反差较大的文本显示、CAD显示和黑白照片显示等方面，高对比度产品在黑白反差、清晰度、完整性等方面都具有优势。相对而言，在色彩层次方面，高对比度对图案的影响并不明显。
