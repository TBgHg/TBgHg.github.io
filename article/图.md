## 图（Graph）

### 一、历史背景

#### 1.哥尼斯堡七桥问题

<center><a href="https://imgchr.com/i/rrMbzd"><img src="https://s3.ax1x.com/2020/12/22/rrMbzd.jpg" alt="rrMbzd.jpg" border="0" /></a></center>
<center>图1-1</center>

一笔画充要条件：

1.图是连通的。

2.图中的“奇点”个数为0或2.

如果“奇点”个数为2，就可以回到起点。

结论：四个点全为”奇点“，不能。

#### 2.哈密顿环球旅行问题

<center><a href="https://imgchr.com/i/rrU3Ct"><img src="https://s3.ax1x.com/2020/12/22/rrU3Ct.jpg" alt="rrU3Ct.jpg" border="0" /></a></center>
<center>图1-2</center>


结论：可以。

注：目前为止没有找到充要条件。

### 二、图的相关概念

#### 1.图的定义

在计算机科学中，一个图就是一些顶点的集合，这些顶点通过一系列边结对（连接），通常表示为：G=(V，E)
注：G表示一个图，V是图G中顶点的集合，E是图G中顶点之间边的集合。

#### 2.基本概念

① 无向边：顶点vi和vj之间的边没有方向，表示为(vi,vj)；

② 无向图：图的任意两个顶点之间的边都是无向边；

③ 有向边：从顶点vi到vj的边有方向，表示为<vi,vj>；

④ 有向图：图的任意两个顶点之间的边都是有向边；

⑤ 简单图：图中不存在顶点到其自身的边，且同一条边不重复出现；

⑥ 邻接、依附：无向图中，对于任意两个顶点vi和顶点vj，若存在边(vi，vj)，则称顶点vi和顶点vj互为邻接点，同时称边(vi，vj)依附于顶点vi和顶点vj；

⑦ 无向完全图：在无向图中，如果任意两个顶点之间都存在边，则称该图为无向完全图；

⑧ 有向完全图：在有向图中，如果任意两个顶点之间都存在方向相反的两条有向边，则称该图为有向完全图；

⑨ 有向无环图（DAG）：一个无回路的有向图称为有向无环图。

#### 3.基本术语

① 稀疏图：称点较多而边数很少的图为稀疏图；

② 稠密图：称点较少而边数很多的图为稠密图；

③ 顶点的入度：在有向图中，以顶点v为头的边的数目称为顶点v的入度，记为ID (v)；

④ 顶点的出度：在有向图中，以顶点v为尾的边的数目称为顶点v的出度，记为OD (v)；

⑤ 顶点的度：在无向图中，顶点v的度是指依附于顶点v的边数，通常记为TD (v)，在有向图中，顶点v的度是其入度和出度的和；

⑥ 权：是指对边赋予的有意义的数值量；

⑦ 网：边上带权的图，也称网图；

⑧ 路径：在无向图G=(V, E)中，从顶点vp到顶点vq之间的路径是一个顶点序列(vp=vi0,vi1,vi2, …,vim=vq)，其中，(vij-1,vij)∈E（1≤j≤m），若G是有向图，则路径也是有方向的，顶点序列满足<vij-1,vij>∈E；

⑨ 路径长度：对于非带权图是路径上边的个数；对于带权图是路径上各边的权之和；

⑩ 回路（环）：第一个顶点和最后一个顶点相同的路径。

⑪ 简单路径：序列中顶点不重复出现的路径。

⑫ 简单回路（简单环）：除了第一个顶点和最后一个顶点外，其余顶点不重复出现的回路。

⑬ 子图：若图G=（V，E），G’=（V’，E’），如果V’ ⊆ V 且E’ ⊆ E ，则称图G’是G的子图。

⑭ 连通图：在无向图中，如果从一个顶点vi到另一个顶点vj(i≠j)有路径，则称顶点vi和vj是连通的。如果图中任意两个顶点都是连通的，则称该图是连通图。

⑮ 连通分量：非连通图的极大连通子图称为连通分量。

⑯ 强连通图：在有向图中，对图中任意一对顶点vi和vj (i≠j)，若从顶点vi到顶点vj和从顶点vj到顶点vi均有路径，则称该有向图是强连通图。

⑰ 强连通分量：非强连通图的极大强连通子图。

⑱ 生成树：一个有 n 个结点的连通图的生成树是原图的极小连通子图，且包含原图中的所有 n 个结点，并且有保持图连通的最少的边

⑲ 生成森林：在非连通图中，由每个连通分量都可以得到一棵生成树，这些连通分量的生成树就组成了一个非连通图的生成森林。

### 三、图的存储

#### 1.邻接矩阵法

邻接矩阵一般适用于存储点集较小的图，图形表示及代码表示都较为简单。

要建立一个邻接矩阵，首先要定义一个一维数组，和一个二维数组。一维数组用来存储图中的所有顶点信息。二维数组用来存储所有边的信息。这里，先假设V为图的顶点集，E为图的边集。

例如：顶点1与顶点2之间的边，可以表示为E(1)(2)。对应邻接矩阵的相应位置。结点数为n的图G=（V，E）的邻接矩阵A是n阶方阵。

对于无权图来说，如果两个顶点之间没有线相连，则在矩阵的对应位置用0表示；反之，有线相连则用1来表示。

对于有权图来说，有线相连则对应位置的值为权值，无线相连对应位置为无穷大。

有向图和无向图原理类似，E(4)(1)表示由4指向1。

下图给出了有向图和无向图的邻接矩阵存储方式

<center><a href="https://imgchr.com/i/rrOupd"><img src="https://s3.ax1x.com/2020/12/22/rrOupd.png" alt="rrOupd.png" border="0" /></a></center>
<center>图1-1</center>

图的邻接矩阵存储结构定义如下：

```c
#define MaxVnum 100					//顶点的最大值为100
typedef char V_Type					//顶点的数据类型
typedef int E_Type  				//带权图中边权值的数据类型
 
typedef struct{						
    V_Type Vex[MaxVnum];			//顶点表
    E_Type Edge[MaxVnum][MaxVnum];  //边表
    int vexnum,arcnum;				//图当前的顶点数和弧数
}Graph;

```

【注】1.邻接矩阵表示法的空间复杂度为O（n²）,其中n为图的顶点数V；

#### 2.邻接表法

对于图来说，邻接矩阵是不错的一种图存储结构，但是我们也发现，对于边数相对顶点较少的图，这种结构是存在对存储空间的极大浪费的。因此我们考虑另外一种存储结构方式：邻接表，即数组与链表相结合的存储方法。

邻接表的处理方法是这样的。

1、图中顶点用一个一维数组存储，另外，对于顶点数组中，每个数据元素还需要存储指向第一个邻接点的指针，以便于查找该顶点的边信息。当然，也可以建立一个顶点的结点去存储顶点信息的边头指针，结构如下:

<center><a href="https://imgchr.com/i/rsPTsg"><img src="https://s3.ax1x.com/2020/12/22/rsPTsg.png" alt="rsPTsg.png" border="0" /></a></center>
<center>图2-1</center>


2、图中每个顶点vi的所有邻接点构成一个线性表，由于邻接点的个数不定，所以用单链表存储，无向图称为顶点vi的边表，有向图称为顶点vi作为弧尾的出边表。边表的结点结构如下：

<center><a href="https://imgchr.com/i/rsih79"><img src="https://s3.ax1x.com/2020/12/22/rsih79.png" alt="rsih79.png" border="0" /></a></center>
<center>图2-2</center>

下图是一个无向表的邻接表结构：

<center><a href="https://imgchr.com/i/rsFPc8"><img src="https://s3.ax1x.com/2020/12/22/rsFPc8.jpg" alt="rsFPc8.jpg" border="0" /></a></center>
<center>图2-3</center>

若是有向图，邻接表的结构是类似的，以顶点作为弧尾来存储边表容易得到每个顶点的出度，而以顶点为弧头的表容易得到顶点的入度，即逆邻接表。结构如下图：

<center><a href="https://imgchr.com/i/rsFU9x"><img src="https://s3.ax1x.com/2020/12/22/rsFU9x.jpg" alt="rsFU9x.jpg" border="0" /></a></center>
<center>图2-4</center>

对于带权值的网图，可以在边表结点定义中再增加一个weight的数据域，存储权值信息即可：

<center><a href="https://imgchr.com/i/rsF2Ct"><img src="https://s3.ax1x.com/2020/12/22/rsF2Ct.jpg" alt="rsF2Ct.jpg" border="0" /></a></center>
<center>图2-5</center>


图的邻接表存储结构定义如下：

```c
#define MaxVNum 100					//定义顶点最大值为100

typedef struct ArcNode{				//边表结点
	int adjvex;						//该弧所指向的顶点位置
	struct ArcNode *next;			//指向下一条弧的指针
}ArcNode;

typedef struct VNode{				//顶点表结点
	VertexType data;				//顶点信息
	ArcNode *first;					//指向第一条依附该结点的弧的指针
}ANode,AdjList[MaxVNum];

typedef struct{						//邻接表
	AdjList vertices;				//图的顶点数和弧数
	int vexnum,arcnum;				//ALGraph是以邻接表存储的图类型
}
```

### 四、图的遍历

#### 1.深度优先搜索（DFS）

深度优先搜索遍历是沿着图的某一条分支遍历直到末端，然后回溯，再沿着另一条进行同样的遍历，直到所有的顶点都被访问为止。

​                                        																																			——啊哈！算法

一般是利用递归，并用book数组记录一个点是否遍历。


<center><a href="https://imgchr.com/i/s92740"><img src="https://s3.ax1x.com/2021/01/03/s92740.png" alt="s92740.png" border="0" /></a></center>
<center>图1-1</center>


代码如下：

```c++
void DFS(int cur)
{
	static int sum=0;
	int i;
	if(sum==N-1)
		return;

	book[cur]=1;
	printf("%d\t",cur);
	sum++;

	for(i=1;i<N;i++)
	{
		if(w[cur][i]==1&&book[i]==0)
			DFS(i);
	}
}

void DFS_link(int cur)
{
	static int sum=0;
	edge* p;
	

	book[cur]=1;
	printf("%d\t",cur);
	sum++;
	if(sum==N-1)
		return;
	
	for(p=vertex[cur];p!=NULL;p=p->next)
	{
		if(book[p->to]==0)
			DFS_link(p->to);		
	}
}
```



#### 2.广度优先搜索（BFS）

广度优先搜索是一层一层的遍历，主要利用了队列。

广度应该好理解一些，就是把能够连接的顶点全部加入队列中。

代码如下：

```c++
void BFS(int cur)
{
	int i;
	q.push(cur);
	book[cur]=1;

	while(!q.empty())        //如果空了，说明全部遍历了
	{
		cur=q.front();   
		q.pop();				//把队列中第一个元素弹出来
		printf("%d\t",cur);
		

		for(i=1;i<N;i++)
		{
			if(w[cur][i]<M&&book[i]!=1)
			{
				q.push(i);     	//将连通的顶点全部加入到队列中
				book[i]=1;			//标记已经遍历了的顶点
			}						//很明显循环的最后几次应该没有加入新的顶点
		}
	}	 
}

void BFS_link(int cur)
{
	edge* p;
	q.push(cur);
	book[cur]=1;

	while(!q.empty())
	{
		cur=q.front();
		q.pop();
		printf("%d\t",cur);
		
		for(p=vertex[cur];p!=NULL;p=p->next)
		{
			if(book[p->to]==0)
			{
				q.push(p->to);
				book[p->to]=1;
			}
		}
	}
}
```



### 五、最短路

#### 5.1 Floyd算法

​    Floyd算法是一个经典的动态规划算法，它又被称为插点法。该算法名称以创始人之一、1978年图灵奖获得者、斯坦福大学计算机科学系教授罗伯特·弗洛伊德命名。Floyd算法是一种利用动态规划的思想寻找给定的加权图中多源点之间最短路径的算法,算法目标是寻找从点i到点j的最短路径。

​    在一个有权图中，找到的最短路径可以分成直接，间接两种。顾名思义，最短路径可以是两点直接连接的距离，也可以是经过其他点的距离之和。要确定最终的最短路径到底是哪一种，需要我们去比较两者。当然，间接距离也需要内部比较。为了方便算法的正常运行，我们可以不断更新直接路径的数值，每一次比较后，将新的最短路径赋值给直接路径。遍历完图中所有的点之后，便可以知道整个图中两点间的最短距离。

   下面是算法的详细过程。

   首先，需要创建一个初始矩阵。记录所有点的两点之间直接距离，如果两点之间并不相连，则记作无穷大。如图所示：

<center><a href="https://imgchr.com/i/s9kgbD"><img src="https://s3.ax1x.com/2021/01/03/s9kgbD.png" alt="s9kgbD.png" border="0" /></a></center>
<center>图1-1</center>

​    接下来，我们需要按顺序将图中的每一个点标记为路径，例如，我们将1标为路径，那么2和3之间的距离便不再是无穷大，而是变成了3到1加上1到2，也就是5了。

​    每一次标记完，都需要更新矩阵，将无穷大变成数字。已经有数字的位置，如果出现了第二个路径，则需要跟原来的路径比较大小，将小的路径填入其中。

​    例如：当第一次1被标记为路径之后，从2到4的元素被赋值为8（6+2），然而当3被标记为路径后，由于经过3的路径长度小于不经过3的路径长度，2、4元素被重新赋值为7，后来5被标记为路径，该元素再次更新为5，由此，得出两点之间的最短距离为5。

​    该算法用数学的语言描述如下：

<center><a href="https://imgchr.com/i/s9EEm8"><img src="https://s3.ax1x.com/2021/01/03/s9EEm8.png" alt="s9EEm8.png" border="0" /></a></center>
<center>图1-2</center>
代码实现如下：

```c
void Floyd(Graph G)
{
	int A[NUMS][NUMS],path[NUMS][NUMS];
	int i,j,k;
	for (i=0;i<G.n;i++)
	{
		for (j=0;j<G.n;j++)
		{
			A[i][j]=G.edges[i][j];
			path[i][j]=-1;
		}
	}
	for (k=0;k<G.n;k++)
	{
		for (i=0;i<G.n;i++)
		{
			for (j=0;j<G.n;j++)
			{
				if (A[i][j]>A[i][k]+A[k][j])
				{
					A[i][j]=A[i][k]+A[k][j];
					path[i][j]=k;
				}
			}
		}
	}
	Dispath(A,path,G.n);
}
```

首先自然要创建一个图，将这个图写入矩阵中。无穷大则用`#define INF 65535`代替。

依次遍历，依次更新，在最终得出的矩阵中找到对应的间距值即可。

优点：容易理解，可以算出任意两个节点之间的最短距离，代码编写简单

缺点：时间复杂度比较高，不适合计算大量数据。

时间复杂度:O(n³)

空间复杂度:O(n² )



#### 5.2  Dijkstra算法

​    Dijkstra算法算是贪心思想实现的，首先把起点到所有点的距离存下来找个最短的，然后松弛一次再找出最短的，所谓的松弛操作就是，遍历一遍看通过刚刚找到的距离最短的点作为中转站会不会更近，如果更近了就更新距离，这样把所有的点找遍之后就存下了起点到其他所有点的最短距离。

​    算法的详细思路如下：

​    首先，我们需要创建一个一维数组，每个元素代表起始点与该点的距离，两者之间无连接仍用无穷大表示。如图所示：

<center><a href="https://imgchr.com/i/s9l7M4"><img src="https://s3.ax1x.com/2021/01/03/s9l7M4.png" alt="s9l7M4.png" border="0" /></a></center>
<center>图2-1</center>

<center><a href="https://imgchr.com/i/s9lxJK"><img src="https://s3.ax1x.com/2021/01/03/s9lxJK.png" alt="s9lxJK.png" border="0" /></a></center>
<center>图2-2</center>

从起始点1开始，依次寻找它所连接的最短路径。并且更新数组。这里需要用到松弛操作，也就是，即使已经存在路径的点，遍历时依然要与之比较，经过新中转点的点是否比原路径更短。最后可以得到全部遍历的最短路径集合数组。

<center><a href="https://imgchr.com/i/s93GBd"><img src="https://s3.ax1x.com/2021/01/03/s93GBd.png" alt="s93GBd.png" border="0" /></a></center>
<center>图2-3</center>

算法的代码实现如下：

```c
void Dijkstra(int u)
{
	memset(vis,0,sizeof(vis));
	for(int t=1;t<=n;t++)
	{
		dis[t]=map[u][t];
	}
	vis[u]=1;
	for(int t=1;t<n;t++)
	{
		int minn=Inf,temp;
		for(int i=1;i<=n;i++)
		{
			if(!vis[i]&&dis[i]<minn)
			{
				minn=dis[i];
				temp=i;
			}
		}
		vis[temp]=1;
		for(int i=1;i<=n;i++)
		{
			if(map[temp][i]+dis[temp]<dis[i])
			{
				dis[i]=map[temp][i]+dis[temp];
			}
		}
	}
	
}
```

### 六、最小生成树

####    (一)Pim算法

Pim算法主要将顶点一个一个加进来。

首先建立一个集合（树），先随便找一个顶点，再后找离这个顶点最近的顶点，将其加入树中。

然后再找离树中顶点距离最短的顶点，再加入树中。

<center><a href="https://imgchr.com/i/s9yAJS"><img src="https://s3.ax1x.com/2021/01/03/s9yAJS.jpg" alt="s9yAJS.jpg" border="0" /></a></center>
<center>图1-1</center>

```c++
#include<cstdio>                   
#define N 6
#define M 99
using namespace std;
int weight[N][N] =
{
	0,0,0,0,0,0,
	0,M,1,3,M,M,
	0,1,M,3,6,M,
	0,3,3,M,4,2,
	0,M,6,4,M,5,
	0,M,M,2,5,M
};
int book[N] = { 0 };
typedef struct
{
	int from;
	int wei;
	int to;
}tree;
typedef struct  
{
	int min;
	int to;
}ver;
ver find(int(*w)[N],int cur)
{
	int i;              //找出离cur顶点距离最小的顶点
	ver a;
	for (a.min = M, i = 1; i < N; i++)
	{
		if (w[cur][i] < a.min && book[i] == 0)  //这个顶点必须是不在树中的
		{
			a.min = w[cur][i];
			a.to = i;
		}
	}

	return a;
}
int main()
{
	int i,j;
	ver flag,temp;
	tree t[N-1];
	book[1] = 1;				//从1开始
	for(j=1;j<N-1;j++)     //找4次即可，一共就5个顶点
	{
		flag.min = M;
		for (i = 1; i < N; i++)
		{
			if (book[i] == 1)        //判断这个顶点是否在树中
			{
				temp = find(weight, i);         //如果在，就找离他最近的点   
				if (flag.min > temp.min)
				{
					flag = temp;                   //看看其他顶点的最近顶点是不是更近一些
					t[j].from = i;
				}								//最终得到离树中顶点最近的一个顶点
			}     
		}
		t[j].wei = flag.min;
		t[j].to = flag.to;
		book[flag.to] = 1;
	}

	for (i = 1; i < N-1; i++)
		printf("%d\t%d\t%d\n\n", t[i].from, t[i].wei, t[i].to);
}

```



#### （二）Kruskal算法

##### 1. 前置知识——并查集

Kruskal算法需要用到并查集来判断是否形成了环，所以在介绍Kruskal算法前，先介绍并查集。

###### 1-1 引入

并查集主要用于解决一些元素分组的问题。它管理一系列不相交的集合，并支持两种操作：
① 合并（Union）：把两个不相交的集合合并为一个集合。
② 查询（Find）：查询两个元素是否在同一个集合中。

举一个题目作为例子：（洛谷P1551 亲戚）

[![s9pnHA.png](https://s3.ax1x.com/2021/01/03/s9pnHA.png)](https://imgchr.com/i/s9pnHA)

<center>图1-1-1</center>

在这个问题中，我们可以把人抽象为元素，划分到若干个互不相交的集合中去，每个集合内的元素都互相是亲戚关系。这道题就可以考虑用并查集来做。以下关于基本流程的说明将按本题中形象化的名词“亲戚”来展开说明。

###### 1-2 基本流程

在并查集中，每个集合有一个唯一的“爸爸”。假设现在有6个元素，先初始化，将每个元素自己当做一个集合，并且设定自己是自己的“爸爸”。如图1-2-1。

<center><a href="https://imgchr.com/i/s99JG6"><img src="https://s3.ax1x.com/2021/01/03/s99JG6.jpg" alt="s99JG6.jpg" border="0" /></a></center>
<center>图1-2-1</center>

接着，有指令需要将1号元素和3号元素设为“亲戚”，即把1号和3号元素所在集合连接起来。对于这一步操作，我们让3号元素的“爸爸”认1号元素当“爸爸”即可。因为3号元素现在的“爸爸”是他自己，所以将3号元素的“爸爸”设为1号元素即可。如图1-2-2。（注：将1号元素的“爸爸”设为3号也可以，这里的顺序并不重要）

<center><a href="https://imgchr.com/i/s9F06f"><img src="https://s3.ax1x.com/2021/01/03/s9F06f.jpg" alt="s99JG6.jpg" border="0" /></a></center>
<center>图1-2-2</center>

然后我们用同样的方法让1号和2号、4号和5号、4号和6号元素成为“亲戚”。如图1-2-3。

<center><a href="https://imgchr.com/i/s9FvjK"><img src="https://s3.ax1x.com/2021/01/03/s9FvjK.jpg" alt="s9FvjK.jpg" border="0" /></a></center>
<center>图1-2-3</center>

需要注意的是，已经是“亲戚”的，就不需要再“认亲戚”了。如何判断两个元素是不是亲戚呢？这就涉及到并查集的“查询”操作。我们只需要看看两个元素他们的“祖先”是否一样即可判断他们是不是“亲戚”。找元素的“祖先”，也就是不断寻找这个元素的“爸爸”的“爸爸”的“爸爸”......直到找到某个元素自己是自己的“爸爸”，这个元素就是“祖先”。

接下来，我们总结一种更普遍的“认亲戚”方式。假设现在要连接3号和5号元素，我们先找到5号元素的“祖先”。在图1-2-3中，5号的“祖先”是4号，我们将“祖先”的“爸爸”设为3号。这就是并查集的“合并”操作。

更进一步，由于我们找“祖先”的过程需要一步一步往上找，但并查集只是表示集合的关系，具体的连接方式并不重要，所以我们可以将5号元素的“祖先”的“爸爸”设为3号元素的“祖先”，这样在下次找“祖先”时可以少走几步。如图1-2-4。

<center><a href="https://imgchr.com/i/s9EdpR"><img src="https://s3.ax1x.com/2021/01/03/s9EdpR.png" alt="s9EdpR.png" border="0" /></a></center>
<center>图1-2-4</center>

事实上，一个元素的“祖先”和它的“爸爸”的“祖先”应当是一样的。再进一步，可以想到在找“祖先”的过程中，我们在找到“祖先”后，把中间的若干代“爸爸”的“爸爸”设为“祖先”，如此操作后，下次找“祖先”时便节省了很多步骤。这就是并查集的“路径压缩”。

###### 1-3 代码实现

初始化，将每个元素的“爸爸”设为自己。a数组存储元素的“爸爸”的序号，即a[i]表示i号元素的“爸爸”的序号。

```c++
for (int i=1; i<=n; ++i)
	a[i] = i;
```

找“祖先”操作（带路径压缩）

```c++
int getFather(int x)
{
	if (a[x] == x)
		return x;
	int tmp = getFather(a[x]);
	return a[x]=tmp;
}
```

“合并”操作

```c++
void merge(int x, int y)
{
	a[getFather(x)] = getFather(y);
}
```

“查询”操作 (输出‘Y’表示在一个集合，‘N’表示不在一个集合)

```c++
if (getFather(x) == getFather(y))
	printf ("Y\n");
else
	printf ("N\n");
```

##### 2. 用Kruskal算法解决最小生成树问题

###### 2-1 基本思想

Kruskal算法用到了贪心的思想，总体来说按边来找最小生成树，所以相较于Prim算法更适用于稀疏图。

Kruskal算法的贪心策略为：

① 将每个节点自己作为一个独立的集合。

② 将图的每条边按照边权值升序排序。

③ 从边权值最小的边开始依次向后找边，若该边连接的两个点不在一个集合内，就把该边边权加到答案中，并把这两个集合合并起来。

④ 找完边之后即可得到答案。

###### 2-2 关于Kruskal算法的正确性的证明

由于采用了贪心策略，所以需要对其正确性进行证明。

设T为Kruskal算法构造出的生成树，U是G的最小生成树。如果T==U那么证明结束。如果T != U，我们就需要证明T和U的构造代价相同。由于T != U，所以一定存在k > 0条边存在于T中，却不在U中。接下来，我们做k次变换，每次从T中取出一条不在U中的边放入U，然后删除U一条不在T中的边，最后使T和U的边集相同。每次变换中，把T中的一条边e加入U，同时删除U中的一条边f。e、f按如下规则选取：a). e是在T中却不在U中的边的最小的一条边；b). e加入U后，肯定构成唯一的一个环路，令f是这个环路中的一条边，但不在T中。f一定存在，因为T中没有环路。
这样的一次变换后，U仍然是一棵生成树。
我们假设e权值小于f，这样变换后U的代价一定小于变换前U的代价，而这和我们之前假设U是最小生成树矛盾，因此e权值不小于f。
再假设e权值大于f。由于f权值小于e，由Kruskal算法知，f在e之前从E中取出，但被舍弃了。一定是由于和权值小于等于f的边构成了环路。但是T中权值小于等于f（小于e）的边一定存在于U中，而f在U中却没有和它们构成环路，又推出矛盾。所以e权值不大于f。于是e权值等于f。
这样，每次变换后U的代价都不变，所以K次变换后，U和T的边集相同，且代价相同，这样就证明了T也是最小生成树。由证明过程可以知道，最小生成树可以不是唯一的。

###### 2-3 代码实现

有了并查集的铺垫，我们可以给出Kruskal算法的代码实现。

edge数组存储边信息，p数组存储集合关系。

```c++
struct Edge
{
	int u;
	int v;
	int w;
}edge[MAXN];
int p[5005];
```

并查集的找“祖先”函数（带路径压缩）

```c++
int getFather(int x)
{
    return p[x]==x?x:p[x]=getFather(p[x]);
}
```

读入数据并初始化并查集

```c++
int n, m;
long long cnt = 0; //存储答案
scanf ("%d%d", &n, &m);
for (int i=1; i<=n; ++i)
    p[i] = i;
for (int i=0; i<m; ++i)
{
    scanf ("%d%d%d", &edge[i].u, &edge[i].v, &edge[i].w);
}
```

将edge数组排序

```c++
bool cmp(Edge x, Edge y)
{
    return x.w < y.w;
}

sort(edge, edge+m, cmp);
```

贪心扫边并输出答案

```c++
for (int i=0; i<m; ++i)
{
    x0 = getFather(edge[i].u);
    y0 = getFather(edge[i].v);
    if (x0 != y0)
    {
        cnt += edge[i].w;
        p[x0] = y0;
    }
}
printf ("%lld", cnt);
```

#### （三）Prim与Kruskal算法的时间复杂度的比较

Prim算法：O(n²) (n为顶点个数)
Kruskal算法：O(mlgm) (m为边的个数)

在连通图中：n-1 ≤ m ≤ n*(n-1)/2

如果一个图的边数m接近上述下限（这个图是非常稀疏的），则Kruskal算法的时间复杂度为O(nlgn)，这意味着Kruskal算法应当更快速一些。但是，如果一个图的边数接近上限（这个图是非常稠密的），则Kruskal算法的时间复杂度为O(n²lgn)，这意味着Prim算法应当更快速一些。
